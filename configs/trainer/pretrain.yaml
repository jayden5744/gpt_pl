epochs: 100
learning_rate:  5e-5
batch_size: 64

# logging
save_step: 1000 # 모델 저장할 스텝
print_train_step: 10
print_valid_step: 100


# optimizer
optimizer: "AdamW"   # choice of [Adam, AdamW]
optimizer_b1: 0.9
optimizer_b2: 0.999
optimizer_e: 1e-08
weight_decay: 0.01

# Regularization
early_stopping: 30
label_smoothing_value: 0.1