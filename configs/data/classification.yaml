project_name: "gpt_scratch"
dataset_name: "naver_movie_corpus"
task: "classification"

language: "ko"

train_path: "data/${data.dataset_name}/train.txt"
valid_path: "data/${data.dataset_name}/valid.txt"

tokenizer_type: "bpe" # coice of [unigram, bpe, char, word]

pretrain_path: "SavedModel/pretrain/pretrain-v9.ckpt"
dictionary_path: "dictionary/pretrain"
model_path: "SavedModel/${data.project_name}/${data.dataset_name}"

vocab_size: 30000 # 30000 # 논문에서는 4만